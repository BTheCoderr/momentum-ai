#!/usr/bin/env python3
"""
FAISS-based Vector Store Service
Handles embeddings, storage, and similarity search
"""
import os
import json
import pickle
import numpy as np
import faiss
from typing import List, Dict, Any, Optional, Tuple
import requests
from datetime import datetime

class FAISSVectorStore:
    def __init__(self, dimension: int = 768, index_path: str = "data/vector_store"):
        """
        Initialize FAISS vector store
        
        Args:
            dimension: Embedding dimension (768 for nomic-embed-text)
            index_path: Path to store the index files
        """
        self.dimension = dimension
        self.index_path = index_path
        self.index_file = os.path.join(index_path, "faiss_index.bin")
        self.metadata_file = os.path.join(index_path, "metadata.json")
        
        # Create directory if it doesn't exist
        os.makedirs(index_path, exist_ok=True)
        
        # Initialize FAISS index
        self.index = faiss.IndexFlatIP(dimension)  # Inner product for cosine similarity
        self.metadata: List[Dict[str, Any]] = []
        
        # Load existing index if available
        self.load_index()
    
    def get_embedding(self, text: str) -> np.ndarray:
        """
        Get embedding for text using Ollama's nomic-embed-text model
        
        Args:
            text: Text to embed
            
        Returns:
            numpy array of embeddings
        """
        try:
            payload = {
                "model": "nomic-embed-text",
                "prompt": text
            }
            
            response = requests.post(
                'http://localhost:11434/api/embeddings',
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                embedding = np.array(result['embedding'], dtype=np.float32)
                
                # Normalize for cosine similarity
                embedding = embedding / np.linalg.norm(embedding)
                
                return embedding
            else:
                raise Exception(f"Embedding API error: {response.status_code}")
                
        except Exception as e:
            print(f"Error getting embedding: {e}")
            # Return random embedding as fallback
            return np.random.random(self.dimension).astype(np.float32)
    
    def add_document(self, text: str, metadata: Dict[str, Any]) -> int:
        """
        Add a document to the vector store
        
        Args:
            text: Document text
            metadata: Document metadata
            
        Returns:
            Document ID
        """
        # Get embedding
        embedding = self.get_embedding(text)
        
        # Add to FAISS index
        self.index.add(embedding.reshape(1, -1))
        
        # Store metadata
        doc_id = len(self.metadata)
        doc_metadata = {
            "id": doc_id,
            "text": text,
            "timestamp": datetime.now().isoformat(),
            **metadata
        }
        self.metadata.append(doc_metadata)
        
        # Save index
        self.save_index()
        
        return doc_id
    
    def search(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """
        Search for similar documents
        
        Args:
            query: Search query
            k: Number of results to return
            
        Returns:
            List of similar documents with scores
        """
        if self.index.ntotal == 0:
            return []
        
        # Get query embedding
        query_embedding = self.get_embedding(query)
        
        # Search
        scores, indices = self.index.search(query_embedding.reshape(1, -1), k)
        
        results = []
        for i, (score, idx) in enumerate(zip(scores[0], indices[0])):
            if idx < len(self.metadata):
                result = {
                    "score": float(score),
                    "rank": i + 1,
                    **self.metadata[idx]
                }
                results.append(result)
        
        return results
    
    def add_user_data(self, user_id: str, data_type: str, content: str, extra_metadata: Dict[str, Any] = None):
        """
        Add user-specific data to the vector store
        
        Args:
            user_id: User identifier
            data_type: Type of data (checkin, goal, reflection, etc.)
            content: Text content
            extra_metadata: Additional metadata
        """
        metadata = {
            "user_id": user_id,
            "data_type": data_type,
            "content": content,
            **(extra_metadata or {})
        }
        
        return self.add_document(content, metadata)
    
    def search_user_data(self, user_id: str, query: str, data_type: str = None, k: int = 5) -> List[Dict[str, Any]]:
        """
        Search user-specific data
        
        Args:
            user_id: User identifier
            query: Search query
            data_type: Filter by data type
            k: Number of results
            
        Returns:
            Filtered search results
        """
        results = self.search(query, k * 2)  # Get more results to filter
        
        # Filter by user_id and data_type
        filtered_results = []
        for result in results:
            if result.get("user_id") == user_id:
                if data_type is None or result.get("data_type") == data_type:
                    filtered_results.append(result)
                    if len(filtered_results) >= k:
                        break
        
        return filtered_results
    
    def get_user_context(self, user_id: str, query: str, context_types: List[str] = None) -> Dict[str, Any]:
        """
        Get comprehensive user context for RAG
        
        Args:
            user_id: User identifier
            query: Current query/context
            context_types: Types of context to retrieve
            
        Returns:
            Structured context for RAG
        """
        if context_types is None:
            context_types = ["checkin", "goal", "reflection", "mood", "activity"]
        
        context = {
            "query": query,
            "user_id": user_id,
            "relevant_data": {}
        }
        
        for data_type in context_types:
            results = self.search_user_data(user_id, query, data_type, k=3)
            context["relevant_data"][data_type] = results
        
        return context
    
    def save_index(self):
        """Save FAISS index and metadata to disk"""
        try:
            # Save FAISS index
            faiss.write_index(self.index, self.index_file)
            
            # Save metadata
            with open(self.metadata_file, 'w') as f:
                json.dump(self.metadata, f, indent=2)
                
        except Exception as e:
            print(f"Error saving index: {e}")
    
    def load_index(self):
        """Load FAISS index and metadata from disk"""
        try:
            if os.path.exists(self.index_file):
                self.index = faiss.read_index(self.index_file)
                print(f"‚úÖ Loaded FAISS index with {self.index.ntotal} documents")
            
            if os.path.exists(self.metadata_file):
                with open(self.metadata_file, 'r') as f:
                    self.metadata = json.load(f)
                print(f"‚úÖ Loaded metadata for {len(self.metadata)} documents")
                
        except Exception as e:
            print(f"Error loading index: {e}")
    
    def get_stats(self) -> Dict[str, Any]:
        """Get vector store statistics"""
        return {
            "total_documents": self.index.ntotal,
            "dimension": self.dimension,
            "index_type": "IndexFlatIP",
            "metadata_count": len(self.metadata),
            "index_file_exists": os.path.exists(self.index_file),
            "metadata_file_exists": os.path.exists(self.metadata_file)
        }

# Example usage and testing
if __name__ == "__main__":
    # Initialize vector store
    vs = FAISSVectorStore()
    
    print("üöÄ FAISS Vector Store Demo")
    print("=" * 50)
    
    # Add sample documents
    sample_docs = [
        {
            "text": "I had a great workout today, feeling energized and motivated!",
            "metadata": {"user_id": "user1", "data_type": "checkin", "mood": "positive"}
        },
        {
            "text": "Struggling with motivation lately, need to get back on track",
            "metadata": {"user_id": "user1", "data_type": "reflection", "mood": "low"}
        },
        {
            "text": "My goal is to exercise 5 times a week and eat healthier",
            "metadata": {"user_id": "user1", "data_type": "goal", "category": "fitness"}
        },
        {
            "text": "Completed my morning meditation, feeling calm and focused",
            "metadata": {"user_id": "user1", "data_type": "activity", "category": "wellness"}
        }
    ]
    
    # Add documents
    for doc in sample_docs:
        doc_id = vs.add_document(doc["text"], doc["metadata"])
        print(f"üìÑ Added document {doc_id}: {doc['text'][:50]}...")
    
    print(f"\nüìä Vector Store Stats: {vs.get_stats()}")
    
    # Test search
    print("\nüîç Testing Search:")
    query = "motivation and exercise"
    results = vs.search(query, k=3)
    
    for result in results:
        print(f"Score: {result['score']:.3f} | {result['text'][:60]}...")
    
    # Test user context
    print("\nüß† Testing User Context:")
    context = vs.get_user_context("user1", "I need help with motivation")
    print(f"Context types: {list(context['relevant_data'].keys())}")
    
    print("\n‚úÖ FAISS Vector Store working perfectly!") 